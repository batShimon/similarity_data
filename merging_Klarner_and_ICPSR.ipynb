{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date:** Dec 17, 2024 \n",
    "**Author:** Revekka Gershovich\n",
    "**Purpose:** Align and merge ICPSR dataset (1834-1975) and Klarner dataset (1935-2011)\n",
    "**Preceded by Cleaning_icpsr16_partisan_composition.ipynb file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a different data source available from **Carl Klarner** for years 1935-2011. It can be found in raw_data_dir folder called Klarner_stateComposition. The folder contains two datasets. The one I load as klarner1 contains the actual data cleaned by Klarner while klarner2 contains data about the data sources from which the dataset was derived along with multiple parameters re: how various data sources recorded various data point. All of this is recorded in Word documents that are in the same folder. This documentation also explains how odd states are handled. \n",
    "\n",
    "Tha paper in the folder discusses problems such as legislature switches mid_session and biases that come from a bad measure of party control. We have to accept many of those problems due to the fact that they are only solved in this dataset after 1935 and we have to use a less reliable source for before then. \n",
    "\n",
    "### My next steps: \n",
    "1. Bring data to the format in which all the data is which involves renaming variables and computing measures of proportions of dems and reps in session, i.e. in both legislative chambers. \n",
    "2. Filtering both ICPRS and Klarner datasets to overlap years, i.e. 1935-1975, and merging those two datasets to see the discrepancies so as to resolve any or at least inconsistencies between the two datasets coding\n",
    "3. Dropping the years after 1935 from ICPSR dataset since it is less reliable of the sources, and appending Klarner dataset to it. \n",
    "4. I also have ncsl_state_composition data for years after 2011, that I will append after all that is done\n",
    "5. The final step would be to append data for all US governors that I downloaded from here: https://github.com/jacobkap/governors, and making sure that the rest of my data is consistent with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(\"/Users/revekkagershovich/Dropbox (MIT)/StateLaws\")\n",
    "os.chdir(parent_dir)\n",
    "assert os.path.exists(parent_dir), \"parent_dir does not exist\"\n",
    "intermed_data_dir = \"./2_data/2_intermediate/political_data\"\n",
    "assert os.path.exists(intermed_data_dir), \"Data directory does not exist\"\n",
    "raw_data_dir = \"./2_data/1_raw/political_data/all_partisanComposition\"\n",
    "assert os.path.exists(raw_data_dir), \"Data directory does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpsr = pd.read_csv(os.path.join(intermed_data_dir, \"icpsr.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Klarner Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keeping this cell so that you can easily load the data with info re: data sources\n",
    "\n",
    "# klarner2 = pd.read_excel(os.path.join(raw_data_dir, \"Klarner_partisan_composition/StatePartisanBalance1934to2011_SourceFiles_2011_05_24.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for how many states is missing each year?\n",
      "election_year\n",
      "2011    50\n",
      "2012    50\n",
      "2013    50\n",
      "2014    50\n",
      "1934    50\n",
      "1933    49\n",
      "1935    45\n",
      "1942     2\n",
      "1946     2\n",
      "1945     2\n",
      "1944     2\n",
      "1943     2\n",
      "1938     2\n",
      "1941     2\n",
      "1940     2\n",
      "1939     2\n",
      "1937     2\n",
      "1936     2\n",
      "1947     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load Karl Klarner's dataset for years 1934-2011\n",
    "klarner1_0 = pd.read_excel(os.path.join(raw_data_dir, \"Klarner_partisan_composition/Partisan_Balance_For_Use2011_06_09b.xlsx\"))\n",
    "\n",
    "# Define columns to check for missing data\n",
    "columns_to_check = [\n",
    "    'govparty_c', 'sen_dem_prop_all', 'sen_rep_prop_all', 'hs_dem_prop_all', 'hs_rep_prop_all',\n",
    "    'sen_dem_in_sess', 'sen_rep_in_sess', 'sen_tot_in_sess',\n",
    "    'hs_dem_in_sess', 'hs_rep_in_sess', 'hs_tot_in_sess'\n",
    "]\n",
    "\n",
    "# Create a boolean mask identifying rows where all `columns_to_check` are NA\n",
    "mask = klarner1_0[columns_to_check].isna().all(axis=1)\n",
    "\n",
    "identifiers = ['year', 'election_year', 'state', 'stateno', 'fips']\n",
    "\n",
    "# Create a boolean mask identifying rows where all columns other than identifiers are NA\n",
    "NA_mask = klarner1_0.loc[:, ~klarner1_0.columns.isin(identifiers)].isna().all(axis=1)\n",
    "\n",
    "# Identify rows where all columns other than identifiers are NA\n",
    "NaN_data = klarner1_0[mask]\n",
    "\n",
    "# Inspect the distribution of `election_year` for NaN data\n",
    "print(\"Data for how many states is missing each year?\")\n",
    "print(NaN_data['election_year'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output it is clear that for years 2011-2014 and 1934, all states formally exist in the data but all variables of interest apart from identificator columns are missing. \n",
    "Most data also seems to be missing for years 1934 and 1935 (or not all states were present in the data to begin with). And for years 1936-1947 data for two states is missing. I will now find out for which states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "election_year\n",
      "1936    [Alaska, Hawaii]\n",
      "1937    [Alaska, Hawaii]\n",
      "1938    [Alaska, Hawaii]\n",
      "1939    [Alaska, Hawaii]\n",
      "1940    [Alaska, Hawaii]\n",
      "1941    [Alaska, Hawaii]\n",
      "1942    [Alaska, Hawaii]\n",
      "1943    [Alaska, Hawaii]\n",
      "1944    [Alaska, Hawaii]\n",
      "1945    [Alaska, Hawaii]\n",
      "1946    [Alaska, Hawaii]\n",
      "1947    [Alaska, Hawaii]\n",
      "Name: state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define years of interest to filter rows to drop\n",
    "years_of_interest = [1942, 1946, 1945, 1944, 1943, 1938, 1941, 1940, 1939, 1937, 1936, 1947]\n",
    "\n",
    "# Filter rows to drop for the specific years of interest\n",
    "filtered_rows = NaN_data[NaN_data['election_year'].isin(years_of_interest)]\n",
    "\n",
    "# Group by `election_year` and list unique states for each year\n",
    "states_by_year = filtered_rows.groupby('election_year')['state'].unique()\n",
    "\n",
    "# Display the states grouped by `election_year`\n",
    "print(states_by_year)  \n",
    "# Alaska and Hawaii data are missing for years 1936-1947 because they joined in 1959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states in data for each election year:\n",
      "election_year\n",
      "1935     5\n",
      "1936    48\n",
      "1937    48\n",
      "1938    48\n",
      "1939    48\n",
      "        ..\n",
      "2006    50\n",
      "2007    50\n",
      "2008    50\n",
      "2009    50\n",
      "2010    50\n",
      "Name: count, Length: 76, dtype: int64\n",
      "['Kentucky' 'Mississippi' 'New Jersey' 'Virginia' 'New York']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove rows where all `columns_to_check` are NA from `klarner1_0`\n",
    "klarner_noNAs = klarner1_0[~mask]\n",
    "\n",
    "# Print the count of `election_year` values, ordered by year\n",
    "print(\"Number of states in data for each election year:\")\n",
    "print(klarner_noNAs['election_year'].value_counts().sort_index())\n",
    "\n",
    "# When we drop all columns with NAs in non_dentification columns,\n",
    "# we drop all observations before 1935 and after 2010, and in 1935 we only have five states.\n",
    "\n",
    "# Filter data for 1935 and list unique states\n",
    "states_1935 = klarner_noNAs[klarner_noNAs['election_year'] == 1935]['state'].unique()\n",
    "\n",
    "# Display the result\n",
    "print(states_1935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the columns that are needed for the analysis\n",
    "klarner1 = klarner_noNAs[['state', 'election_year', 'sen_dem_prop_all', 'sen_rep_prop_all', 'hs_dem_prop_all', \n",
    "'hs_rep_prop_all', 'sen_dem_in_sess', 'sen_rep_in_sess', 'sen_tot_in_sess', 'hs_dem_in_sess', \n",
    "'hs_rep_in_sess', 'hs_tot_in_sess', 'govparty_c']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  dem_upphse  rep_upphse  dem_lowhse  \\\n",
      "473   1962           ID        2.0    0.477273    0.522727    0.460317   \n",
      "1705  1964           UT        1.0    0.555556    0.444444    0.565217   \n",
      "1683  2006           TX        2.0    0.354839    0.645161    0.460000   \n",
      "366   1969           GA        1.0    0.875000    0.125000    0.856410   \n",
      "1728  2003           UT        2.0    0.241379    0.758621    0.253333   \n",
      "\n",
      "      rep_lowhse  shr_dem_in_sess  shr_rep_in_sess  \n",
      "473     0.539683         0.467290         0.532710  \n",
      "1705    0.434783         0.562500         0.437500  \n",
      "1683    0.540000         0.441989         0.558011  \n",
      "366     0.138461         0.860558         0.135458  \n",
      "1728    0.746667         0.250000         0.750000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dictionary mapping state names to abbreviations\n",
    "state_to_abbrev = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
    "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT',\n",
    "    'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', \n",
    "    'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', \n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', \n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', \n",
    "    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}\n",
    "\n",
    "# Add a new column to the DataFrame with the abbreviations\n",
    "klarner1.loc[:, 'state_abbrev'] = klarner1['state'].map(state_to_abbrev)\n",
    "\n",
    "# Since in ICPSR I only have state abbreviations, I will drop the column containing the full state names\n",
    "klarner1 = klarner1.drop(columns=['state'])\n",
    "\n",
    "# Rename the columns to match the ICPSR dataset\n",
    "klarner1 = klarner1.rename(columns={\n",
    "    'election_year': 'year',\n",
    "    'govparty_c': 'gov_party',\n",
    "    'sen_dem_prop_all': 'dem_upphse',\n",
    "    'sen_rep_prop_all': 'rep_upphse',\n",
    "    'hs_dem_prop_all': 'dem_lowhse',\n",
    "    'hs_rep_prop_all': 'rep_lowhse',\n",
    "})\n",
    "\n",
    "# Keeping only the final dataset columns and the columns needed to calculate the share of Democrats and Republicans in the session\n",
    "klarner1 = klarner1[[\n",
    "    'year', 'state_abbrev', 'gov_party',\n",
    "    'dem_upphse', 'rep_upphse', 'dem_lowhse', 'rep_lowhse',\n",
    "    'sen_dem_in_sess', 'sen_rep_in_sess', 'sen_tot_in_sess',\n",
    "    'hs_dem_in_sess', 'hs_rep_in_sess', 'hs_tot_in_sess'\n",
    "]]\n",
    "\n",
    "# Calculate the overall share of Democratic and Republican seats in the session (upper + lower house) - this measure is not available in the dataset\n",
    "klarner1['shr_dem_in_sess'] = (klarner1['sen_dem_in_sess'] + klarner1['hs_dem_in_sess']) / (klarner1['hs_tot_in_sess'] + klarner1['sen_tot_in_sess'])\n",
    "klarner1['shr_rep_in_sess'] = (klarner1['sen_rep_in_sess'] + klarner1['hs_rep_in_sess']) / (klarner1['hs_tot_in_sess'] + klarner1['sen_tot_in_sess'])\n",
    "\n",
    "# Drop the columns that were used for calculating overall share of dem/rep seats in the session and are not needed anymore\n",
    "klarner1 = klarner1.drop(columns=['sen_dem_in_sess', 'sen_rep_in_sess', 'sen_tot_in_sess', 'hs_dem_in_sess', 'hs_rep_in_sess', 'hs_tot_in_sess'])\n",
    "\n",
    "# In the Klarner dataset democrats are coded as 1 like I map ICPSR data, but Republicans are coded as 0, not 2. \n",
    "# I will change this to match ICPSR data. Value 0.5 signify non-major party governor, however I was just \n",
    "# dropping those values in ICPSR data, and they are automatically dropped with the mapping.\n",
    "klarner1['gov_party'] = klarner1['gov_party'].map({1.0: 1, 0.0: 2})\n",
    "\n",
    "print(klarner1.sample(5, random_state = 44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states: 50\n"
     ]
    }
   ],
   "source": [
    "# Check the number of unique states\n",
    "print(f\"Number of unique states: {klarner1['state_abbrev'].nunique()}\")\n",
    "\n",
    "# Assertions\n",
    "assert klarner1['state_abbrev'].nunique() == 50, \"There should be 50 states.\"\n",
    "\n",
    "assert klarner1['year'].min() == 1935, \"The minimum year should be 1935.\"\n",
    "assert klarner1['year'].max() == 2010, \"The maximum year should be 2010 because the election year should be off-set one year back.\"\n",
    "assert klarner1['year'].nunique() == 76, \"There should be 76 unique years.\"\n",
    "\n",
    "assert klarner1['gov_party'].nunique() == 2, \"There should be 2 unique parties.\"\n",
    "\n",
    "# Check if all values in 'gov_party' are valid\n",
    "valid_values = {1, 2}  \n",
    "assert klarner1['gov_party'].dropna().isin(valid_values).all(), \"All values in 'gov_party' should be 1, 2, or NaN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that Klarner data is cleaned and brought to the standart format, I will filter ICPSR and Klarner data to contain only the years that are in both datasets, i.e. 1935-1975. The idea is to make sure that this data is the same in both datasets, and then apply the coding to the rest of the data to make sure that it is consistent across all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing ICPSR and Klarner Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ICPSR and Klarner data to keep only years in both datasets, i.e. 1935-1975\n",
    "icpsr_filt = icpsr[icpsr['year'] >= 1935]\n",
    "klarner_filt = klarner1[klarner1['year'] <= 1975]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing datasets for even years only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering both datasets only for even years to see if they align for the even years \n",
    "# at least since odd yeats are more tricky.\n",
    "icpsr_filt_even = icpsr_filt[icpsr_filt['year'] % 2 == 0]\n",
    "klarner_filt_even = klarner_filt[klarner_filt['year'] % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets only for even years to be able to compare the data from both sources\n",
    "merged_even = pd.merge(klarner_filt_even, icpsr_filt_even, \n",
    "on=['year', 'state_abbrev'], suffixes=('_klarner', '_icpsr'), how='outer')\n",
    "\n",
    "# Reorder the columns\n",
    "merged_even = merged_even[['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr',\n",
    "                           'dem_upphse_klarner', 'dem_upphse_icpsr', 'rep_upphse_klarner', \n",
    "                           'rep_upphse_icpsr', 'dem_lowhse_klarner', 'dem_lowhse_icpsr', \n",
    "                           'rep_lowhse_klarner', 'rep_lowhse_icpsr', 'shr_dem_in_sess_klarner', \n",
    "                           'shr_dem_in_sess_icpsr', 'shr_rep_in_sess_klarner', 'shr_rep_in_sess_icpsr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 rows where 'gov_party_klarner' is not equal to 'gov_party_icpsr'.\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_gov_even = merged_even[\n",
    "    merged_even['gov_party_klarner'].notna() & \n",
    "    merged_even['gov_party_icpsr'].notna() & \n",
    "    (merged_even['gov_party_klarner'] != merged_even['gov_party_icpsr'])\n",
    "]\n",
    "print(f\"There are {unequal_rows_gov_even.shape[0]} rows where 'gov_party_klarner' is not equal to 'gov_party_icpsr'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_icpsr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1938</td>\n",
       "      <td>OH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1942</td>\n",
       "      <td>NY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1948</td>\n",
       "      <td>WY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1950</td>\n",
       "      <td>CO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1954</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1958</td>\n",
       "      <td>NY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>1964</td>\n",
       "      <td>UT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1966</td>\n",
       "      <td>UT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>1968</td>\n",
       "      <td>MD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>1968</td>\n",
       "      <td>UT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year state_abbrev  gov_party_klarner  gov_party_icpsr\n",
       "80   1938           OH                2.0              1.0\n",
       "175  1942           NY                2.0              1.0\n",
       "337  1948           WY                2.0              1.0\n",
       "343  1950           CO                2.0              1.0\n",
       "471  1954           NY                1.0              2.0\n",
       "571  1958           NY                2.0              1.0\n",
       "731  1964           UT                1.0              2.0\n",
       "781  1966           UT                1.0              2.0\n",
       "807  1968           MD                1.0              2.0\n",
       "831  1968           UT                1.0              2.0"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unequal_rows_gov_even[['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows that are mismatched between Klarner and the correct data: 0\n",
      "Number of rows that are mismatched between ICPSR and the correct data: 10\n",
      "Thus it is clear that Klarner is the more accurate dataset, and all the instances of mismatch are due to errors in ICPSR data.\n"
     ]
    }
   ],
   "source": [
    "# Here is a dataset to double-check the problematic years with links to sources generated by ChatGPT\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    \"year\": [1938, 1942, 1948, 1950, 1954, 1958, 1964, 1966, 1968, 1968],\n",
    "    \"state_abbrev\": [\"OH\", \"NY\", \"WY\", \"CO\", \"NY\", \"NY\", \"UT\", \"UT\", \"MD\", \"UT\"],\n",
    "    \"governor\": [\n",
    "        \"John W. Bricker\", \"Thomas E. Dewey\", \"Arthur G. Crane\", \"Daniel I.J. Thornton\",\n",
    "        \"W. Averell Harriman\", \"Nelson A. Rockefeller\", \"Cal Rampton\", \"Cal Rampton\",\n",
    "        \"Marvin Mandel\", \"Cal Rampton\"\n",
    "    ],\n",
    "    \"party_code\": [2, 2, 2, 2, 1, 2, 1, 1, 1, 1],\n",
    "    \"source_url\": [\n",
    "        \"https://en.wikipedia.org/wiki/1938_Ohio_gubernatorial_election\",\n",
    "        \"https://en.wikipedia.org/wiki/1942_New_York_state_election\",\n",
    "        \"https://en.wikipedia.org/wiki/List_of_governors_of_Wyoming\",\n",
    "        \"https://en.wikipedia.org/wiki/1950_Colorado_gubernatorial_election\",\n",
    "        \"https://en.wikipedia.org/wiki/1954_New_York_state_election\",\n",
    "        \"https://en.wikipedia.org/wiki/1958_New_York_state_election\",\n",
    "        \"https://en.wikipedia.org/wiki/1964_Utah_gubernatorial_election\",\n",
    "        \"https://en.wikipedia.org/wiki/List_of_governors_of_Utah\",\n",
    "        \"https://en.wikipedia.org/wiki/List_of_governors_of_Maryland\",\n",
    "        \"https://en.wikipedia.org/wiki/List_of_governors_of_Utah\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "gov_mismatch = pd.DataFrame(data)\n",
    "\n",
    "# Perform an inner merge to compare rows based on 'year' and 'state_abbrev'\n",
    "comparison = unequal_rows_gov_even.merge(gov_mismatch, on=['year', 'state_abbrev'], how='inner')\n",
    "\n",
    "# Identify mismatched rows where 'gov_party_klarner' does not match 'party_code'\n",
    "mismatched_rows_klarner = comparison[comparison['gov_party_klarner'] != comparison['party_code']]\n",
    "\n",
    "# Display the mismatched rows\n",
    "print(f\"Number of rows that are mismatched between Klarner and the correct data: {mismatched_rows_klarner.shape[0]}\")\n",
    "\n",
    "# Identify mismatched rows where 'gov_party_icpsr' does not match 'party_code'\n",
    "mismatched_rows_icpsr = comparison[comparison['gov_party_icpsr'] != comparison['party_code']]\n",
    "\n",
    "# Display the mismatched rows\n",
    "print(f\"Number of rows that are mismatched between ICPSR and the correct data: {mismatched_rows_icpsr.shape[0]}\")\n",
    "\n",
    "print(\"Thus it is clear that Klarner is the more accurate dataset, and all the instances of mismatch are due to errors in ICPSR data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 131 rows where 'dem_upphse_klarner' is not equal to 'dem_upphse_icpsr'.\n",
      "    year state_abbrev  dem_upphse_klarner  dem_upphse_icpsr\n",
      "0   1936           AL                 NaN          1.000000\n",
      "14  1936           KY            0.684211               NaN\n",
      "22  1936           MS            1.000000               NaN\n",
      "42  1936           VA            0.950000               NaN\n",
      "44  1936           WA            0.804348          0.891304\n",
      "62  1938           KY            0.736842               NaN\n",
      "63  1938           LA            1.000000               NaN\n",
      "70  1938           MS            1.000000               NaN\n"
     ]
    }
   ],
   "source": [
    "# Identify rows where 'dem_upphse_klarner' and 'dem_upphse_icpsr' are not close, excluding rows where both are NaN\n",
    "unequal_rows_dem_upphse = merged_even[\n",
    "    ~np.isclose(merged_even['dem_upphse_klarner'], merged_even['dem_upphse_icpsr'], atol=0.05) &\n",
    "    ~(merged_even['dem_upphse_klarner'].isna() & merged_even['dem_upphse_icpsr'].isna())\n",
    "]\n",
    "\n",
    "unequal_rows_dem_upphse = unequal_rows_dem_upphse[['year', 'state_abbrev', 'dem_upphse_klarner', 'dem_upphse_icpsr']]\n",
    "\n",
    "# Print the number of rows where the values are not equal\n",
    "print(f\"There are {unequal_rows_dem_upphse.shape[0]} rows where 'dem_upphse_klarner' is not equal to 'dem_upphse_icpsr'.\")\n",
    "\n",
    "# Display the mismatched rows\n",
    "print(unequal_rows_dem_upphse.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_abbrev\n",
       "MS    19\n",
       "VA    19\n",
       "KY    18\n",
       "NJ    12\n",
       "MN    12\n",
       "LA     9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that out of 6 states for which mismatch occurs most often, \n",
    "# five states have odd-year state elections, i.e. MA, VA, KY, NJ, and LA which \n",
    "# suggests that they are coded differently in the two datasets.\n",
    "unequal_rows_dem_upphse['state_abbrev'].value_counts().head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dem_upphse_icpsr\n",
      "NaN    77\n",
      "Name: count, dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [year, state_abbrev, dem_upphse_klarner, dem_upphse_icpsr]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_dem_upphse_odd_states = unequal_rows_dem_upphse[unequal_rows_dem_upphse['state_abbrev'].isin(['MS', 'VA', 'KY', 'NJ', 'LA'])]\n",
    "\n",
    "# # Display the mismatched rows for odd-year state elections\n",
    "# print(unequal_rows_dem_upphse_odd_states)\n",
    "\n",
    "print(unequal_rows_dem_upphse_odd_states['dem_upphse_icpsr'].value_counts(dropna = False))\n",
    "# We can see that the ICPSR data has a lot of missing values for these states in eveh years where Klarner does not meaning \n",
    "# in ICPSR the data is only available for the actual election years.\n",
    "\n",
    "print(unequal_rows_dem_upphse_odd_states.dropna()) \n",
    "# In the remaining rows it seems like ICPSR values are just rounded up Klarner values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year state_abbrev  dem_upphse_klarner  dem_upphse_icpsr\n",
      "0    1936           AL                 NaN          1.000000\n",
      "44   1936           WA            0.804348          0.891304\n",
      "113  1940           MD            0.793103               NaN\n",
      "171  1942           NH            0.291667          0.375000\n",
      "183  1942           TN            0.848485          0.909091\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_dem_upphse_only_even_states = unequal_rows_dem_upphse[~unequal_rows_dem_upphse['state_abbrev'].isin(['MS', 'VA', 'KY', 'NJ', 'LA'])]\n",
    "\n",
    "# Display the mismatched rows for even-year state elections\n",
    "print(unequal_rows_dem_upphse_only_even_states.head())\n",
    "\n",
    "# Mostly those differences are small, and are probably caused by adjustments in the Klarner dataset or mistakes/missing data in icpsr data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state_abbrev  dem_upphse_klarner  dem_upphse_icpsr\n",
      "0  1936           AL                 NaN               1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_icpsr</th>\n",
       "      <th>dem_upphse_klarner</th>\n",
       "      <th>dem_upphse_icpsr</th>\n",
       "      <th>rep_upphse_klarner</th>\n",
       "      <th>rep_upphse_icpsr</th>\n",
       "      <th>dem_lowhse_klarner</th>\n",
       "      <th>dem_lowhse_icpsr</th>\n",
       "      <th>rep_lowhse_klarner</th>\n",
       "      <th>rep_lowhse_icpsr</th>\n",
       "      <th>shr_dem_in_sess_klarner</th>\n",
       "      <th>shr_dem_in_sess_icpsr</th>\n",
       "      <th>shr_rep_in_sess_klarner</th>\n",
       "      <th>shr_rep_in_sess_icpsr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1936</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year state_abbrev  gov_party_klarner  gov_party_icpsr  dem_upphse_klarner  \\\n",
       "0  1936           AL                1.0              1.0                 NaN   \n",
       "\n",
       "   dem_upphse_icpsr  rep_upphse_klarner  rep_upphse_icpsr  dem_lowhse_klarner  \\\n",
       "0               1.0                 NaN               0.0                 NaN   \n",
       "\n",
       "   dem_lowhse_icpsr  rep_lowhse_klarner  rep_lowhse_icpsr  \\\n",
       "0          0.990566                 NaN          0.009434   \n",
       "\n",
       "   shr_dem_in_sess_klarner  shr_dem_in_sess_icpsr  shr_rep_in_sess_klarner  \\\n",
       "0                      NaN               0.992908                      NaN   \n",
       "\n",
       "   shr_rep_in_sess_icpsr  \n",
       "0               0.007092  "
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter and print rows where 'dem_upphse_klarner' is NA\n",
    "print(unequal_rows_dem_upphse_only_even_states[unequal_rows_dem_upphse_only_even_states['dem_upphse_klarner'].isna()])\n",
    "\n",
    "merged_even[(merged_even['state_abbrev'] == 'AL') & (merged_even['year'] == 1936)]\n",
    "\n",
    "# There is missing data for Alabama in 1936 in the Klarner dataset, \n",
    "# and the ICPSR dataset has a value of 0.0 for the Democratic proportion in the upper house which is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 rows where 'rep_upphse_klarner' is not equal to 'rep_upphse_icpsr'.\n",
      "     year state_abbrev  rep_upphse_klarner  rep_upphse_icpsr\n",
      "381  1950           UT            0.304348          0.782609\n",
      "945  1974           DE            0.380952          0.142857\n"
     ]
    }
   ],
   "source": [
    "# Exclude rows already in unequal_rows_dem_upphse\n",
    "remaining_rows = merged_even.loc[~merged_even.index.isin(unequal_rows_dem_upphse.index)]\n",
    "\n",
    "# Identify rows where 'rep_upphse_klarner' and 'rep_upphse_icpsr' are not close, excluding NaN matches\n",
    "unequal_rows_rep_upphse = remaining_rows[\n",
    "    ~np.isclose(remaining_rows['rep_upphse_klarner'], remaining_rows['rep_upphse_icpsr'], atol=0.1) &\n",
    "    ~(remaining_rows['rep_upphse_klarner'].isna() & remaining_rows['rep_upphse_icpsr'].isna())\n",
    "]\n",
    "\n",
    "# Display the results\n",
    "print(f\"There are {unequal_rows_rep_upphse.shape[0]} rows where 'rep_upphse_klarner' is not equal to 'rep_upphse_icpsr'.\")\n",
    "print(unequal_rows_rep_upphse[['year', 'state_abbrev', 'rep_upphse_klarner', 'rep_upphse_icpsr']])\n",
    "# i double-ckecked that Klarner data is correct for the row with a mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 rows where 'rep_upphse_klarner' is not equal to 'rep_upphse_icpsr'.\n",
      "     year state_abbrev  dem_lowhse_klarner  dem_lowhse_icpsr\n",
      "28   1936           NJ            0.350000          0.650000\n",
      "38   1936           SD            0.359223          0.173333\n",
      "46   1936           WV            0.765957          0.872340\n",
      "239  1944           WY            0.500000          0.363636\n",
      "269  1946           NM            0.612245          0.734694\n",
      "337  1948           WY            0.375000          0.500000\n",
      "428  1952           SD            0.026667          0.240000\n",
      "437  1952           WY            0.428571          0.196429\n",
      "478  1954           SD            0.240000          0.360000\n",
      "578  1958           SD            0.426667          0.240000\n",
      "678  1962           SD            0.226667          0.400000\n",
      "902  1972           IN            0.270000          0.464646\n",
      "935  1972           WI            0.626263          0.373737\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_dem_lowhse = remaining_rows[\n",
    "    ~np.isclose(remaining_rows['dem_lowhse_klarner'], remaining_rows['dem_lowhse_icpsr'], atol=0.1) &\n",
    "    ~(remaining_rows['dem_lowhse_klarner'].isna() & remaining_rows['dem_lowhse_icpsr'].isna())\n",
    "]\n",
    "\n",
    "# Display the results\n",
    "print(f\"There are {unequal_rows_dem_lowhse.shape[0]} rows where 'rep_upphse_klarner' is not equal to 'rep_upphse_icpsr'.\")\n",
    "print(unequal_rows_dem_lowhse[['year', 'state_abbrev', 'dem_lowhse_klarner', 'dem_lowhse_icpsr']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Filling 1935-1975 ICPSR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1935     5\n",
      "1936    42\n",
      "1937     4\n",
      "1938    42\n",
      "1939    46\n",
      "1940    42\n",
      "1941     3\n",
      "1942    42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(icpsr_filt['year'].value_counts().sort_index().head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is only available for the actual election years, and not for the odd years in between (or even years for states on odd-year election cycle states). I will forward-fill the ICPSR dataset for each state for each year where data is not available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete grid of years and states\n",
    "years = icpsr_filt['year'].unique()\n",
    "states = icpsr_filt['state_abbrev'].unique()\n",
    "\n",
    "# Create a DataFrame with all combinations\n",
    "all_combos = pd.MultiIndex.from_product([years, states], names=['year', 'state_abbrev']).to_frame(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  rep_upphse\n",
      "1087  1935           AZ        NaN         NaN\n",
      "37    1936           AZ        1.0         0.0\n",
      "1137  1937           AZ        NaN         NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  rep_upphse\n",
      "1087  1935           AZ        NaN         NaN\n",
      "37    1936           AZ        1.0         0.0\n",
      "1137  1937           AZ        1.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Merge the complete grid with the original dataset\n",
    "icpsr_complete = pd.merge(all_combos, icpsr_filt, on=['year', 'state_abbrev'], how='left')\n",
    "\n",
    "print(\n",
    "    icpsr_complete[icpsr_complete['state_abbrev'] == 'AZ']\n",
    "    [['year', 'state_abbrev', 'gov_party', 'rep_upphse']]\n",
    "    .sort_values(by='year', ascending=True)\n",
    "    .head(3)\n",
    ")\n",
    "\n",
    "# Identify identifier columns (e.g., year and state_abbrev)\n",
    "id_cols = ['year', 'state_abbrev']\n",
    "gov_id_cols = ['year', 'state_abbrev', 'gov_party']\n",
    "\n",
    "# Identify non-identifier columns\n",
    "non_id_cols = [col for col in icpsr_complete.columns if col not in id_cols]\n",
    "non_gov_id_cols = [col for col in icpsr_complete.columns if col not in gov_id_cols]\n",
    "\n",
    "# Forward-fill for each state\n",
    "for state in states:\n",
    "    # Subset the data for the current state and sort by year\n",
    "    state_data = icpsr_complete[icpsr_complete['state_abbrev'] == state].sort_values(by='year')\n",
    "    \n",
    "    # Forward-fill non-identifier columns\n",
    "    state_data[non_id_cols] = state_data[non_id_cols].ffill()\n",
    "    \n",
    "    # Forward-fill non-gov_party columns\n",
    "    state_data[non_gov_id_cols] = state_data[non_gov_id_cols].ffill()\n",
    "    \n",
    "    # Update the main DataFrame\n",
    "    icpsr_complete.loc[state_data.index, non_id_cols] = state_data[non_id_cols]\n",
    "    icpsr_complete.loc[state_data.index, non_gov_id_cols] = state_data[non_gov_id_cols]\n",
    "\n",
    "# Display results for AZ\n",
    "print(\n",
    "    icpsr_complete[icpsr_complete['state_abbrev'] == 'AZ']\n",
    "    [['year', 'state_abbrev', 'gov_party', 'rep_upphse']]\n",
    "    .sort_values(by='year', ascending=True)\n",
    "    .head(3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if after forward-filling ICPSR, Klarner and ICPSR data are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'state_abbrev', 'gov_party_klarner', 'dem_upphse_klarner',\n",
      "       'rep_upphse_klarner', 'dem_lowhse_klarner', 'rep_lowhse_klarner',\n",
      "       'shr_dem_in_sess_klarner', 'shr_rep_in_sess_klarner',\n",
      "       'gov_party_icpsr_comp', 'dem_upphse_icpsr_comp',\n",
      "       'rep_upphse_icpsr_comp', 'dem_lowhse_icpsr_comp',\n",
      "       'rep_lowhse_icpsr_comp', 'shr_dem_in_sess_icpsr_comp',\n",
      "       'shr_rep_in_sess_icpsr_comp', 'gov_party', 'dem_upphse', 'rep_upphse',\n",
      "       'dem_lowhse', 'rep_lowhse', 'shr_dem_in_sess', 'shr_rep_in_sess'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merging klarner_filt which a dataset for the same years as icpsr_complete to see if the data aligns\n",
    "merged = pd.merge(klarner_filt, icpsr_complete, on=['year', 'state_abbrev'], suffixes=('_klarner', '_icpsr_comp'), how='outer')\n",
    "merged = pd.merge(merged, icpsr_filt, on=['year', 'state_abbrev'], suffixes=('_klarner', '_icpsr_filt'), how='outer')\n",
    "\n",
    "print(merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26 rows where 'gov_party_klarner' is not equal to 'gov_party'.\n",
      "year\n",
      "1938     1\n",
      "1939    16\n",
      "1942     1\n",
      "1948     1\n",
      "1950     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display rows where 'gov_party_klarner' is not equal to 'gov_party_icpsr'\n",
    "unequal_rows_gov = merged[\n",
    "    merged['gov_party_klarner'].notna() &\n",
    "    merged['gov_party'].notna() &\n",
    "    (merged['gov_party_klarner'] != merged['gov_party_icpsr_comp'])\n",
    "]\n",
    "\n",
    "print(f\"There are {unequal_rows_gov.shape[0]} rows where 'gov_party_klarner' is not equal to 'gov_party'.\")\n",
    "\n",
    "# print(unequal_rows_gov)\n",
    "print(unequal_rows_gov['year'].value_counts().sort_index().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "unequal_rows_gov_ev = unequal_rows_gov[unequal_rows_gov['year'] % 2 == 0]\n",
    "assert unequal_rows_gov_ev.shape[0] == 10, \"There should be 10 rows because that's the number of mismatched observations before forward-filling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 144 rows where 'gov_party_klarner' is not equal to 'gov_party_icpsr_comp'.\n",
      "state_abbrev\n",
      "NE    23\n",
      "MD     8\n",
      "UT     8\n",
      "VA     6\n",
      "FL     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_gov = merged[\n",
    "    merged['gov_party_klarner'].notna() &\n",
    "    merged['gov_party_icpsr_comp'].notna() &\n",
    "    merged['gov_party'].isna() &\n",
    "    (merged['gov_party_klarner'] != merged['gov_party_icpsr_comp'])\n",
    "]\n",
    "\n",
    "print(f\"There are {unequal_rows_gov.shape[0]} rows where 'gov_party_klarner' is not equal to 'gov_party_icpsr_comp'.\")\n",
    "\n",
    "print(unequal_rows_gov['state_abbrev'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_icpsr_comp</th>\n",
       "      <th>gov_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1935</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1936</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1937</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1938</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1939</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1940</td>\n",
       "      <td>NE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1941</td>\n",
       "      <td>NE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1942</td>\n",
       "      <td>NE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1943</td>\n",
       "      <td>NE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1944</td>\n",
       "      <td>NE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year state_abbrev  gov_party_klarner  gov_party_icpsr_comp  gov_party\n",
       "28   1935           NE                NaN                   NaN        NaN\n",
       "78   1936           NE                1.0                   NaN        NaN\n",
       "128  1937           NE                1.0                   NaN        NaN\n",
       "178  1938           NE                1.0                   NaN        NaN\n",
       "228  1939           NE                1.0                   1.0        1.0\n",
       "278  1940           NE                2.0                   1.0        NaN\n",
       "328  1941           NE                2.0                   1.0        NaN\n",
       "378  1942           NE                2.0                   1.0        NaN\n",
       "428  1943           NE                2.0                   1.0        NaN\n",
       "478  1944           NE                2.0                   1.0        NaN"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['state_abbrev'] == 'NE'][['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr_comp', 'gov_party']].head(10)\n",
    "# unequal_rows_gov[['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr_comp', 'gov_party']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the worst state is Nebraska because in Nebraska legislature is officially nonpartisan.Candidates for the Nebraska Legislature and governors appear on the ballot without party labels during both primary and general elections. One can still deduce what party affiliation they have, and Klarner dataset does. This is not really a problem at all since Nebraska legislature became officially nonpartisan in 1937, i.e. after Klarner data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "unequal_rows_gov = merged[\n",
    "    merged['gov_party_klarner'].notna() &\n",
    "    merged['gov_party_icpsr_comp'].notna() &\n",
    "    (merged['gov_party_klarner'] != merged['gov_party_icpsr_comp'])\n",
    "]\n",
    "\n",
    "unequal_rows_gov = unequal_rows_gov[\n",
    "    (unequal_rows_gov['year'] != 1935) & \n",
    "    (unequal_rows_gov['year'] != 1939) & \n",
    "    ~unequal_rows_gov['year'].between(1970, 1975) &\n",
    "    (unequal_rows_gov['state_abbrev'] != 'NE')\n",
    "]\n",
    "\n",
    "print(unequal_rows_gov.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1969    4\n",
      "1968    2\n",
      "1959    2\n",
      "1955    1\n",
      "1967    1\n",
      "1966    1\n",
      "1965    1\n",
      "1964    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(unequal_rows_gov['year'].value_counts().head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_icpsr_comp</th>\n",
       "      <th>gov_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state_abbrev, gov_party_klarner, gov_party_icpsr_comp, gov_party]\n",
       "Index: []"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unequal_rows_gov[(unequal_rows_gov['year'] > 1971) & (unequal_rows_gov['year'] < 1976)][['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr_comp', 'gov_party']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_icpsr_comp</th>\n",
       "      <th>gov_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state_abbrev, gov_party_klarner, gov_party_icpsr_comp, gov_party]\n",
       "Index: []"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unequal_rows_gov[(unequal_rows_gov['year'] > 1971) & (unequal_rows_gov['year'] < 1976) & (unequal_rows_gov['gov_party'].notna())][['year', 'state_abbrev', 'gov_party_klarner', 'gov_party_icpsr_comp', 'gov_party']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1974    49\n",
       "1970    45\n",
       "1972    45\n",
       "1971     4\n",
       "1939     4\n",
       "1969     3\n",
       "1973     2\n",
       "1942     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icpsr[(icpsr['year'] > 1936) & (icpsr['gov_party'].isna())]['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1840    17\n",
       "1848    12\n",
       "1838    12\n",
       "1844    12\n",
       "1846    12\n",
       "1842    11\n",
       "1841    11\n",
       "1836    11\n",
       "1837    11\n",
       "1845     9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icpsr[(icpsr['year'] < 1933) & (icpsr['gov_party'].isna())]['year'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/212753806.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(klarner_filt, icpsr_complete, on=['year', 'state_abbrev'], suffixes=('_klarner', '_icpsr'), how='outer')\n",
    "\n",
    "# Identify all columns with '_klarner' and '_icpsr' suffixes\n",
    "klarner_cols = [col for col in merged.columns if col.endswith('_klarner')]\n",
    "icpsr_cols = [col.replace('_klarner', '_icpsr') for col in klarner_cols if col.replace('_klarner', '_icpsr') in merged.columns]\n",
    "\n",
    "# Initialize a dictionary to store comparison results\n",
    "comparison_results = {}\n",
    "\n",
    "# Define the error margin\n",
    "error_margin = 0.01\n",
    "\n",
    "# Compare each pair of _klarner and _icpsr columns\n",
    "for klarner_col, icpsr_col in zip(klarner_cols, icpsr_cols):\n",
    "    # Check for mismatched rows within the error margin\n",
    "    mismatched_rows = merged[~np.isclose(merged[klarner_col], merged[icpsr_col], atol=error_margin)]\n",
    "    \n",
    "    # Exclude rows where both are NaN\n",
    "    mismatched_rows = mismatched_rows[\n",
    "        ~(merged[klarner_col].isna() & merged[icpsr_col].isna())\n",
    "    ]\n",
    "    \n",
    "    # Store the mismatches in the dictionary\n",
    "    comparison_results[f\"{klarner_col} vs {icpsr_col}\"] = mismatched_rows[['year', 'state_abbrev', klarner_col, icpsr_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 270 gov_party mismatches.\n",
      "So for gov_party there are 13.2 % of data is mismatched.\n",
      "There are 329 dem_upphse mismatches.\n",
      "So for dem_upphse there are 16.0 % of data is mismatched.\n",
      "There are 347 rep_upphse mismatches.\n",
      "So for rep_upphse there are 16.9 % of data is mismatched.\n",
      "There are 369 dem_lowhse mismatches.\n",
      "So for dem_lowhse there are 18.0 % of data is mismatched.\n",
      "There are 359 rep_lowhse mismatches.\n",
      "So for rep_lowhse there are 17.5 % of data is mismatched.\n",
      "There are 360 shr_dem_in_sess mismatches.\n",
      "So for shr_dem_in_sess there are 17.6 % of data is mismatched.\n",
      "There are 361 shr_rep_in_sess mismatches.\n",
      "So for shr_rep_in_sess there are 17.6 % of data is mismatched.\n"
     ]
    }
   ],
   "source": [
    "# At 0.01 error margin, the percentage of mismatches is less than 20% for all columns. \n",
    "# Not fantastic but passable given the quality of ICPSR data, and the fact that all errors \n",
    "# are propagated by forward-filling.\n",
    "col_types = ['gov_party', 'dem_upphse', 'rep_upphse', 'dem_lowhse', 'rep_lowhse', 'shr_dem_in_sess', 'shr_rep_in_sess']\n",
    "for col_type in col_types:\n",
    "    mismatched_data = comparison_results[f'{col_type}_klarner vs {col_type}_icpsr']\n",
    "    print(f\"There are {mismatched_data.shape[0]} {col_type} mismatches.\")\n",
    "    print(f\"So for {col_type} there are {mismatched_data.shape[0]/merged.shape[0]*100:.1f} % of data is mismatched.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/2829053057.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n"
     ]
    }
   ],
   "source": [
    "# Define the error margin\n",
    "error_margin = 0.1\n",
    "\n",
    "# Compare each pair of _klarner and _icpsr columns\n",
    "for klarner_col, icpsr_col in zip(klarner_cols, icpsr_cols):\n",
    "    # Check for mismatched rows within the error margin\n",
    "    mismatched_rows = merged[~np.isclose(merged[klarner_col], merged[icpsr_col], atol=error_margin)]\n",
    "    \n",
    "    # Exclude rows where both are NaN\n",
    "    mismatched_rows = mismatched_rows[\n",
    "        ~(merged[klarner_col].isna() & merged[icpsr_col].isna())\n",
    "    ]\n",
    "    \n",
    "    # Store the mismatches in the dictionary\n",
    "    comparison_results[f\"{klarner_col} vs {icpsr_col}\"] = mismatched_rows[['year', 'state_abbrev', klarner_col, icpsr_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 270 gov_party mismatches.\n",
      "So for gov_party there are 13.2 % of data is mismatched.\n",
      "There are 111 dem_upphse mismatches.\n",
      "So for dem_upphse there are 5.4 % of data is mismatched.\n",
      "There are 114 rep_upphse mismatches.\n",
      "So for rep_upphse there are 5.6 % of data is mismatched.\n",
      "There are 127 dem_lowhse mismatches.\n",
      "So for dem_lowhse there are 6.2 % of data is mismatched.\n",
      "There are 128 rep_lowhse mismatches.\n",
      "So for rep_lowhse there are 6.2 % of data is mismatched.\n",
      "There are 114 shr_dem_in_sess mismatches.\n",
      "So for shr_dem_in_sess there are 5.6 % of data is mismatched.\n",
      "There are 117 shr_rep_in_sess mismatches.\n",
      "So for shr_rep_in_sess there are 5.7 % of data is mismatched.\n"
     ]
    }
   ],
   "source": [
    "# At 0.1 error margin, the percentage of mismatches is less than 10% for all columns except gov_party (13%).\n",
    "col_types = ['gov_party', 'dem_upphse', 'rep_upphse', 'dem_lowhse', 'rep_lowhse', 'shr_dem_in_sess', 'shr_rep_in_sess']\n",
    "for col_type in col_types:\n",
    "    mismatched_data = comparison_results[f'{col_type}_klarner vs {col_type}_icpsr']\n",
    "    print(f\"There are {mismatched_data.shape[0]} {col_type} mismatches.\")\n",
    "    print(f\"So for {col_type} there are {mismatched_data.shape[0]/merged.shape[0]*100:.1f} % of data is mismatched.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we can see that the forward-filling works but it propagates missing values and errors in the data of which there are plenty in the ICPSR 16 dataset. I will use separate governor's data to ensure accuracy for governors. I will use more accurate Klarner dataset for after 1935. It's not ideal but it's the best we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward filling ICPSR data for before 1935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpsr_filt = icpsr[icpsr['year'] < 1935]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state_abbrev\n",
      "0  1834           CT\n",
      "1  1834           ME\n",
      "2  1834           MA\n",
      "3  1834           NH\n",
      "4  1834           RI\n"
     ]
    }
   ],
   "source": [
    "# Create a complete grid of years and states\n",
    "years = icpsr_filt['year'].unique()\n",
    "states = icpsr_filt['state_abbrev'].unique()\n",
    "\n",
    "# Create a DataFrame with all combinations\n",
    "all_combos = pd.MultiIndex.from_product([years, states], names=['year', 'state_abbrev']).to_frame(index=False)\n",
    "\n",
    "print(all_combos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   statehood_year state_abbrev\n",
      "0            1787           DE\n",
      "1            1787           PA\n",
      "2            1787           NJ\n",
      "3            1788           GA\n",
      "4            1788           CT\n"
     ]
    }
   ],
   "source": [
    "statehood_df = pd.read_csv(os.path.join(raw_data_dir, \"statehood\", \"statehood_data.csv\"))\n",
    "\n",
    "# Extract the year from 'date_entered' and store it in a new column 'year'\n",
    "statehood_df['statehood_year'] = statehood_df['date_entered'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Rename 'abbr' to 'state_abbrev'\n",
    "statehood_df = statehood_df.rename(columns={'abbr': 'state_abbrev'})\n",
    "\n",
    "# Keep only 'year' and 'state_abbrev' columns\n",
    "statehood_df = statehood_df[['statehood_year', 'state_abbrev']]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(statehood_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the statehood data to filter by valid years\n",
    "all_combos = all_combos.merge(statehood_df, on='state_abbrev', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where the year is greater than or equal to the statehood year\n",
    "all_combos = all_combos[all_combos['year'] >= all_combos['statehood_year']].drop(columns=['statehood_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  rep_upphse\n",
      "2308  1912           AZ        NaN         NaN\n",
      "3171  1913           AZ        NaN         NaN\n",
      "2356  1914           AZ        1.0    0.052632\n",
      "3219  1915           AZ        NaN         NaN\n",
      "2404  1916           AZ        2.0    0.263158\n",
      "      year state_abbrev  gov_party  rep_upphse\n",
      "2308  1912           AZ        NaN         NaN\n",
      "3171  1913           AZ        NaN         NaN\n",
      "2356  1914           AZ        1.0    0.052632\n",
      "3219  1915           AZ        1.0    0.052632\n",
      "2404  1916           AZ        2.0    0.263158\n"
     ]
    }
   ],
   "source": [
    "# Merge the complete grid with the original dataset\n",
    "icpsr_complete = pd.merge(all_combos, icpsr_filt, on=['year', 'state_abbrev'], how='left')\n",
    "\n",
    "print(\n",
    "    icpsr_complete[icpsr_complete['state_abbrev'] == 'AZ']\n",
    "    [['year', 'state_abbrev', 'gov_party', 'rep_upphse']]\n",
    "    .sort_values(by='year', ascending=True)\n",
    "    .head()\n",
    ")\n",
    "\n",
    "# Identify identifier columns (e.g., year and state_abbrev)\n",
    "id_cols = ['year', 'state_abbrev']\n",
    "gov_id_cols = ['year', 'state_abbrev', 'gov_party']\n",
    "\n",
    "# Identify non-identifier columns\n",
    "non_id_cols = [col for col in icpsr_complete.columns if col not in id_cols]\n",
    "non_gov_id_cols = [col for col in icpsr_complete.columns if col not in gov_id_cols]\n",
    "\n",
    "# Forward-fill for each state\n",
    "for state in states:\n",
    "    # Subset the data for the current state and sort by year\n",
    "    state_data = icpsr_complete[icpsr_complete['state_abbrev'] == state].sort_values(by='year')\n",
    "    \n",
    "    # Forward-fill non-identifier columns\n",
    "    state_data[non_id_cols] = state_data[non_id_cols].ffill()\n",
    "    \n",
    "    # Forward-fill non-gov_party columns\n",
    "    state_data[non_gov_id_cols] = state_data[non_gov_id_cols].ffill()\n",
    "    \n",
    "    # Update the main DataFrame\n",
    "    icpsr_complete.loc[state_data.index, non_id_cols] = state_data[non_id_cols]\n",
    "    icpsr_complete.loc[state_data.index, non_gov_id_cols] = state_data[non_gov_id_cols]\n",
    "\n",
    "# Display results for AZ\n",
    "print(\n",
    "    icpsr_complete[icpsr_complete['state_abbrev'] == 'AZ']\n",
    "    [['year', 'state_abbrev', 'gov_party', 'rep_upphse']]\n",
    "    .sort_values(by='year', ascending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions\n",
    "assert icpsr_complete['state_abbrev'].nunique() == 48, \"There should be 48 states because the data is before 1935.\"\n",
    "assert icpsr_complete['year'].min() == 1834, \"The minimum year should be 1834.\"\n",
    "assert icpsr_complete['year'].max() == 1934, \"The maximum year should be 1934.\"\n",
    "assert icpsr_complete['year'].nunique() == 101, \"There should be 101 unique years.\"\n",
    "\n",
    "assert icpsr_complete['gov_party'].nunique() == 2, \"There should be 2 unique parties.\"\n",
    "\n",
    "# Check if all values in 'gov_party' are valid\n",
    "valid_values = {1, 2}  \n",
    "assert icpsr_complete['gov_party'].dropna().isin(valid_values).all(), \"All values in 'gov_party' should be 1, 2, or NaN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading ncsl_state_composition data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF is the only format in which the data is available on ncsl website. I first extracted those files into excel format using Adobe Pdf Extraction tool which can be found here: https://www.adobe.com/au/acrobat/roc/blog/how-to-convert-pdf-to-csv.html#:~:text=Adobe%20Acrobat%20online%20services The free tool does not allow bulk extraction. MIT account gives access to upgraded tool with extraction. I then removed the first row manually and everything after \"TOTAL\" field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [00:00<00:00, 92.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing 2009.xlsx\n",
      "Completed processing 2010.xlsx\n",
      "Completed processing 2011.xlsx\n",
      "Completed processing 2012.xlsx\n",
      "Completed processing 2013.xlsx\n",
      "Completed processing 2014.xlsx\n",
      "Completed processing 2015.xlsx\n",
      "Completed processing 2016.xlsx\n",
      "Completed processing 2017.xlsx\n",
      "Completed processing 2018.xlsx\n",
      "Completed processing 2019.xlsx\n",
      "Completed processing 2020.xlsx\n",
      "Completed processing 2021.xlsx\n",
      "Index(['state', 'total_seats', 'total_senate', 'senate_dem', 'senate_rep',\n",
      "       'total_house', 'house_dem', 'house_rep', 'legis_control', 'gov_party',\n",
      "       'state_control', 'year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Folder path where CSV files are stored\n",
    "folder_path = os.path.join(raw_data_dir, \"ncsl_statepartisancomposition\")\n",
    "assert os.path.exists(folder_path), \"Folder path is incorrect\"\n",
    "\n",
    "# List all CSV files in the folder\n",
    "xlsx_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.xlsx') and not f.startswith('~$')])\n",
    "\n",
    "# Efficiently load and concatenate all excel files\n",
    "ncsl_dfs = []  # List to hold individual DataFrames\n",
    "for file in tqdm(xlsx_files):\n",
    "       file_path = os.path.join(folder_path, file)\n",
    "       assert os.path.exists(file_path), \"File path is incorrect\"\n",
    "\n",
    "       # Extract year from the filename (before \".xlsx\")\n",
    "       year = int(file.split('.xlsx')[0])\n",
    "\n",
    "       # Extract tables from the PDF file\n",
    "       ncsl_df = pd.read_excel(file_path)\n",
    "\n",
    "       if file != '2021.xlsx':\n",
    "              ncsl_df.columns = ['state', 'total_seats', 'total_senate', 'senate_dem', 'senate_rep',\n",
    "              'senate_other', 'total_house', 'house_dem', 'house_rep', 'house_other',\n",
    "              'legis_control', 'gov_party', 'state_control']\n",
    "              # Drop columns called 'senate_other' and 'house_other'\n",
    "              ncsl_df = ncsl_df.drop(columns=['senate_other', 'house_other'])\n",
    "              # ncsl_df.head()\n",
    "       else:\n",
    "              # Rename columns manually\n",
    "              ncsl_df.columns = ['state', 'total_seats', 'total_senate', 'senate_dem', 'senate_rep',\n",
    "                     'total_house', 'house_dem', 'house_rep', 'legis_control', 'gov_party', 'state_control']\n",
    "              # ncsl_df.head()\n",
    "\n",
    "       # Remove asterisks from state names in the 'State' column\n",
    "       ncsl_df['state'] = ncsl_df['state'].str.replace(r'\\*', '', regex=True)\n",
    "\n",
    "       # Add the extracted year as a new column \n",
    "       ncsl_df['year'] = year \n",
    "\n",
    "       # Append the modified DataFrame to the list\n",
    "       ncsl_dfs.append(ncsl_df)\n",
    "\n",
    "       print(f\"Completed processing {file}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "ncsl = pd.concat(ncsl_dfs, ignore_index=True)\n",
    "\n",
    "print(ncsl.columns)\n",
    "\n",
    "# Add a new column to the DataFrame with the abbreviations\n",
    "ncsl.loc[:, 'state_abbrev'] = ncsl['state'].map(state_to_abbrev)\n",
    "\n",
    "# Recoding the 'gov_party' column to match ICPSR data\n",
    "ncsl['gov_party'] = ncsl['gov_party'].map({'Dem': 1, 'Rep': 2})\n",
    "\n",
    "# Since in ICPSR I only have state abbreviations, I will drop the column containing the full state names\n",
    "ncsl = ncsl.drop(columns=['state'])\n",
    "\n",
    "ncsl = ncsl.dropna(subset=['state_abbrev'])\n",
    "\n",
    "# Reorder the columns to have identifiers first\n",
    "ncsl = ncsl[['year', 'state_abbrev', 'total_seats', 'total_senate', 'senate_dem', \n",
    "'senate_rep', 'total_house', 'house_dem', 'house_rep', 'legis_control', 'gov_party', 'state_control']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>total_seats</th>\n",
       "      <th>total_senate</th>\n",
       "      <th>senate_dem</th>\n",
       "      <th>senate_rep</th>\n",
       "      <th>total_house</th>\n",
       "      <th>house_dem</th>\n",
       "      <th>house_rep</th>\n",
       "      <th>legis_control</th>\n",
       "      <th>gov_party</th>\n",
       "      <th>state_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>AL</td>\n",
       "      <td>140</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>105</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>Dem</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>AK</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>Split</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>AZ</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>Rep</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>AR</td>\n",
       "      <td>135</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "      <td>28</td>\n",
       "      <td>Dem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009</td>\n",
       "      <td>CA</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>Dem</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year state_abbrev total_seats total_senate senate_dem senate_rep  \\\n",
       "1  2009           AL         140           35         19         13   \n",
       "2  2009           AK          60           20         10         10   \n",
       "3  2009           AZ          90           30         12         18   \n",
       "4  2009           AR         135           35         27          8   \n",
       "5  2009           CA         120           40         26         14   \n",
       "\n",
       "  total_house house_dem house_rep legis_control  gov_party state_control  \n",
       "1         105        62        43           Dem        2.0       Divided  \n",
       "2          40        18        22         Split        2.0       Divided  \n",
       "3          60        25        35           Rep        2.0           Rep  \n",
       "4         100        71        28           Dem        1.0           Dem  \n",
       "5          80        51        29           Dem        2.0       Divided  "
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncsl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_seats       int64\n",
      "total_senate      int64\n",
      "senate_dem      float64\n",
      "senate_rep      float64\n",
      "total_house     float64\n",
      "house_dem       float64\n",
      "house_rep       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# List of columns to convert to numeric\n",
    "numeric_cols = [\n",
    "    'total_seats', 'total_senate', 'senate_dem', 'senate_rep', 'total_house', 'house_dem', 'house_rep'\n",
    "]\n",
    "\n",
    "# Convert specified columns to numeric\n",
    "ncsl[numeric_cols] = ncsl[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Verify the conversion\n",
    "print(ncsl[numeric_cols].dtypes)\n",
    "\n",
    "ncsl['dem_upphse'] = ncsl['senate_dem'] / ncsl['total_senate']\n",
    "ncsl['rep_upphse'] = ncsl['senate_rep'] / ncsl['total_senate']\n",
    "ncsl['dem_lowhse'] = ncsl['house_dem'] / ncsl['total_house']\n",
    "ncsl['rep_lowhse'] = ncsl['house_rep'] / ncsl['total_house']\n",
    "ncsl['shr_dem_in_sess'] = (ncsl['senate_dem'] + ncsl['house_dem']) / ncsl['total_seats']\n",
    "ncsl['shr_rep_in_sess'] = (ncsl['senate_rep'] + ncsl['house_rep']) / ncsl['total_seats']\n",
    "\n",
    "ncsl = ncsl.drop(columns=['total_seats', 'total_senate', 'senate_dem', 'senate_rep', 'total_house', 'house_dem', 'house_rep', 'legis_control', 'state_control'])\n",
    "\n",
    "# Now the year is election year\n",
    "ncsl['year'] = ncsl['year'] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_count_by_year = ncsl.groupby('year')['state_abbrev'].nunique()\n",
    "\n",
    "# Assertions\n",
    "assert (state_count_by_year == 50).all(), \"Not all years have 50 states!\"\n",
    "assert ncsl['year'].min() == 2008, \"The minimum year should be 2008.\"\n",
    "assert ncsl['year'].max() == 2020, \"The maximum year should be 2020.\"\n",
    "assert ncsl['year'].nunique() == 13, \"There should be 12 unique years.\"\n",
    "\n",
    "assert ncsl['gov_party'].nunique() == 2, \"There should be 2 unique parties.\"\n",
    "\n",
    "# Check if all values in 'gov_party' are valid\n",
    "valid_values = {1, 2}  \n",
    "assert ncsl['gov_party'].dropna().isin(valid_values).all(), \"All values in 'gov_party' should be 1, 2, or NaN.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-check that Klarner and NCSL align for 2009-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years in ncsl: [2008 2009 2010]\n",
      "Years in klarner: [2008 2009 2010]\n"
     ]
    }
   ],
   "source": [
    "ncsl_filt = ncsl[(ncsl['year'] <= 2010)]\n",
    "klarner_filt = klarner1[klarner1['year'] >= 2008]\n",
    "\n",
    "print(f\"Years in ncsl: {ncsl_filt['year'].unique()}\")\n",
    "print(f\"Years in klarner: {klarner_filt['year'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(klarner_filt, ncsl_filt, on=['year', 'state_abbrev'], suffixes=('_klarner', '_ncsl'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/600132105.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n"
     ]
    }
   ],
   "source": [
    "# Identify all columns with '_klarner' and '_ncsl' suffixes\n",
    "klarner_cols = [col for col in merged.columns if col.endswith('_klarner')]\n",
    "ncsl_cols = [col.replace('_klarner', '_ncsl') for col in klarner_cols if col.replace('_klarner', '_ncsl') in merged.columns]\n",
    "\n",
    "# Initialize a dictionary to store comparison results\n",
    "comparison_results = {}\n",
    "\n",
    "# Define the error margin\n",
    "error_margin = 0.1\n",
    "\n",
    "# Compare each pair of _klarner and _ncsl columns\n",
    "for klarner_col, ncsl_col in zip(klarner_cols, ncsl_cols):\n",
    "    # Check for mismatched rows within the error margin\n",
    "    mismatched_rows = merged[~np.isclose(merged[klarner_col], merged[ncsl_col], atol=error_margin)]\n",
    "    \n",
    "    # Exclude rows where both are NaN\n",
    "    mismatched_rows = mismatched_rows[\n",
    "        ~(merged[klarner_col].isna() & merged[ncsl_col].isna())\n",
    "    ]\n",
    "    \n",
    "    # Store the mismatches in the dictionary\n",
    "    comparison_results[f\"{klarner_col} vs {ncsl_col}\"] = mismatched_rows[['year', 'state_abbrev', klarner_col, ncsl_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 gov_party mismatches.\n",
      "So for gov_party there are 0.7 % of data is mismatched.\n",
      "There are 0 dem_upphse mismatches.\n",
      "So for dem_upphse there are 0.0 % of data is mismatched.\n",
      "There are 0 rep_upphse mismatches.\n",
      "So for rep_upphse there are 0.0 % of data is mismatched.\n",
      "There are 0 dem_lowhse mismatches.\n",
      "So for dem_lowhse there are 0.0 % of data is mismatched.\n",
      "There are 0 rep_lowhse mismatches.\n",
      "So for rep_lowhse there are 0.0 % of data is mismatched.\n",
      "There are 0 shr_dem_in_sess mismatches.\n",
      "So for shr_dem_in_sess there are 0.0 % of data is mismatched.\n",
      "There are 0 shr_rep_in_sess mismatches.\n",
      "So for shr_rep_in_sess there are 0.0 % of data is mismatched.\n"
     ]
    }
   ],
   "source": [
    "# At 0.1 error margin, the percentage of mismatches is 0 for all columns except gov_party.\n",
    "col_types = ['gov_party', 'dem_upphse', 'rep_upphse', 'dem_lowhse', 'rep_lowhse', 'shr_dem_in_sess', 'shr_rep_in_sess']\n",
    "for col_type in col_types:\n",
    "    mismatched_data = comparison_results[f'{col_type}_klarner vs {col_type}_ncsl']\n",
    "    print(f\"There are {mismatched_data.shape[0]} {col_type} mismatches.\")\n",
    "    print(f\"So for {col_type} there are {mismatched_data.shape[0]/merged.shape[0]*100:.1f} % of data is mismatched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n",
      "/var/folders/6h/20f1xzjj5xx3z0lxd2hqpjzc0000gp/T/ipykernel_36610/1914774426.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  mismatched_rows = mismatched_rows[\n"
     ]
    }
   ],
   "source": [
    "# Define the error margin\n",
    "error_margin = 0.01\n",
    "\n",
    "# Compare each pair of _klarner and _ncsl columns\n",
    "for klarner_col, ncsl_col in zip(klarner_cols, ncsl_cols):\n",
    "    # Check for mismatched rows within the error margin\n",
    "    mismatched_rows = merged[~np.isclose(merged[klarner_col], merged[ncsl_col], atol=error_margin)]\n",
    "    \n",
    "    # Exclude rows where both are NaN\n",
    "    mismatched_rows = mismatched_rows[\n",
    "        ~(merged[klarner_col].isna() & merged[ncsl_col].isna())\n",
    "    ]\n",
    "    \n",
    "    # Store the mismatches in the dictionary\n",
    "    comparison_results[f\"{klarner_col} vs {ncsl_col}\"] = mismatched_rows[['year', 'state_abbrev', klarner_col, ncsl_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 gov_party mismatches.\n",
      "So for gov_party there are 0.7 % of data is mismatched.\n",
      "There are 11 dem_upphse mismatches.\n",
      "So for dem_upphse there are 7.3 % of data is mismatched.\n",
      "There are 8 rep_upphse mismatches.\n",
      "So for rep_upphse there are 5.3 % of data is mismatched.\n",
      "There are 10 dem_lowhse mismatches.\n",
      "So for dem_lowhse there are 6.7 % of data is mismatched.\n",
      "There are 9 rep_lowhse mismatches.\n",
      "So for rep_lowhse there are 6.0 % of data is mismatched.\n",
      "There are 6 shr_dem_in_sess mismatches.\n",
      "So for shr_dem_in_sess there are 4.0 % of data is mismatched.\n",
      "There are 7 shr_rep_in_sess mismatches.\n",
      "So for shr_rep_in_sess there are 4.7 % of data is mismatched.\n"
     ]
    }
   ],
   "source": [
    "# At 0.01 error margin, the percentage of mismatches is less than 10% for all columns except gov_party.\n",
    "col_types = ['gov_party', 'dem_upphse', 'rep_upphse', 'dem_lowhse', 'rep_lowhse', 'shr_dem_in_sess', 'shr_rep_in_sess']\n",
    "for col_type in col_types:\n",
    "    mismatched_data = comparison_results[f'{col_type}_klarner vs {col_type}_ncsl']\n",
    "    print(f\"There are {mismatched_data.shape[0]} {col_type} mismatches.\")\n",
    "    print(f\"So for {col_type} there are {mismatched_data.shape[0]/merged.shape[0]*100:.1f} % of data is mismatched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>gov_party_klarner</th>\n",
       "      <th>gov_party_ncsl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2009</td>\n",
       "      <td>VA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year state_abbrev  gov_party_klarner  gov_party_ncsl\n",
       "94  2009           VA                1.0             2.0"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_results['gov_party_klarner vs gov_party_ncsl'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2009, the Governor of Virginia was Tim Kaine, a member of the Democratic Party. He served as governor from January 14, 2006, to January 16, 2010 thus it is a mistake in ncsl dataset. However 1 mistake in 3 years is great. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatinate all the data\n",
    "Concatinating icpsr_complete (1832-1934), Klarner1 (1935-2010), ncsl (2011-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncsl = ncsl[ncsl['year'] > 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([icpsr_complete, klarner1, ncsl], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions\n",
    "assert final_df['year'].min() == 1834, \"The minimum year should be 2008.\"\n",
    "assert final_df['year'].max() == 2020, \"The maximum year should be 2020.\"\n",
    "assert final_df['year'].nunique() == 187, \"There should be 12 unique years.\"\n",
    "\n",
    "assert final_df['gov_party'].nunique() == 2, \"There should be 2 unique parties.\"\n",
    "\n",
    "# Check if all values in 'gov_party' are valid\n",
    "valid_values = {1, 2}  \n",
    "assert final_df['gov_party'].dropna().isin(valid_values).all(), \"All values in 'gov_party' should be 1, 2, or NaN.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statehood_year</th>\n",
       "      <th>state_abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1787</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1787</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1787</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1788</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1788</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statehood_year state_abbrev\n",
       "0            1787           DE\n",
       "1            1787           PA\n",
       "2            1787           NJ\n",
       "3            1788           GA\n",
       "4            1788           CT"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statehood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1974    51\n",
       "2020    50\n",
       "1967    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['year'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_abbrev\n",
      "LA    2\n",
      "AL    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df[final_df['year'] == 1974]['state_abbrev'].value_counts().head(2))\n",
    "# Clearly the problem is that we have two Louisianas in 1974."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  dem_upphse  rep_upphse  dem_lowhse  \\\n",
      "4675  1974           LA        1.0    0.974359    0.025641    0.961905   \n",
      "4676  1974           LA        1.0    0.974359    0.000000    0.961905   \n",
      "\n",
      "      rep_lowhse  shr_dem_in_sess  shr_rep_in_sess  \n",
      "4675    0.038095         0.965278         0.034722  \n",
      "4676    0.038095         0.965278         0.027778  \n"
     ]
    }
   ],
   "source": [
    "print(final_df[(final_df['state_abbrev'] == 'LA') & (final_df['year'] == 1974)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cross-references both Louisianas against wikipedia: https://en.wikipedia.org/wiki/Political_party_strength_in_Louisiana, and I can see that both are wrong so I am going to substitute them with the correct version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year state_abbrev  gov_party  dem_upphse  rep_upphse  dem_lowhse  \\\n",
      "8176  1974           LA        1.0         1.0         0.0    0.961905   \n",
      "\n",
      "      rep_lowhse  shr_dem_in_sess  shr_rep_in_sess  \n",
      "8176    0.038095         0.972222         0.027778  \n"
     ]
    }
   ],
   "source": [
    "# Remove the two original observations for Louisiana in 1974\n",
    "final_df = final_df[~((final_df['year'] == 1974) & (final_df['state_abbrev'] == 'LA'))]\n",
    "\n",
    "# Total members in Senate and House\n",
    "total_senate = 39\n",
    "total_house = 105\n",
    "total_members = total_senate + total_house\n",
    "\n",
    "# Calculate the new values for shr_dem_in_session and shr_rep_in_session\n",
    "shr_dem_in_sess = (1 * total_senate + 0.961905 * total_house) / total_members\n",
    "shr_rep_in_sess = (0 * total_senate + 0.038095 * total_house) / total_members\n",
    "\n",
    "# Create a new observation for Louisiana in 1974\n",
    "new_observation = pd.DataFrame([{\n",
    "    'year': 1974,\n",
    "    'state_abbrev': 'LA',\n",
    "    'gov_party': 1.0,  # Preserved from the original\n",
    "    'dem_upphse': 1.0,  # Adjusted to 1\n",
    "    'rep_upphse': 0.0,  # Adjusted to 0\n",
    "    'dem_lowhse': 0.961905,  # Preserved from the original\n",
    "    'rep_lowhse': 0.038095,  # Preserved from the original\n",
    "    'shr_dem_in_sess': shr_dem_in_sess,\n",
    "    'shr_rep_in_sess': shr_rep_in_sess\n",
    "}])\n",
    "\n",
    "# Append the new observation to final_df using pd.concat\n",
    "final_df = pd.concat([final_df, new_observation], ignore_index=True)\n",
    "\n",
    "# Display the result for Louisiana in 1974\n",
    "print(final_df[(final_df['year'] == 1974) & (final_df['state_abbrev'] == 'LA')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  state_count\n",
      "0  1787          3.0\n",
      "1  1788         11.0\n",
      "2  1789         12.0\n",
      "3  1790         13.0\n",
      "4  1791         14.0\n",
      "5  1792         15.0\n",
      "6  1793         15.0\n",
      "7  1794         15.0\n",
      "8  1795         15.0\n",
      "9  1796         16.0\n",
      "year\n",
      "2020    50\n",
      "1974    50\n",
      "1967    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the index as a column, starting from 1\n",
    "statehood_df1 = statehood_df.reset_index(drop=False)\n",
    "statehood_df1['index'] = statehood_df1['index'] + 1\n",
    "\n",
    "# Sort the DataFrame by 'statehood_year' and 'index' (if not already sorted)\n",
    "statehood_df1 = statehood_df1.sort_values(by=['statehood_year', 'index'])\n",
    "\n",
    "# Drop all rows except the last one for each 'statehood_year'\n",
    "statehood_df1 = statehood_df1.groupby('statehood_year', group_keys=False).tail(1)\n",
    "\n",
    "# Define the full range of years\n",
    "full_years = pd.DataFrame({'statehood_year': range(1787, 2021)})\n",
    "\n",
    "# Merge with the existing DataFrame to include all years\n",
    "statehood_df1 = pd.merge(full_years, statehood_df1, on='statehood_year', how='left')\n",
    "\n",
    "# Forward-fill to propagate the last known index value to missing years\n",
    "statehood_df1['index'] = statehood_df1['index'].ffill()\n",
    "statehood_df1['state_abbrev'] = statehood_df1['state_abbrev'].ffill()\n",
    "\n",
    "# Ensure the DataFrame is sorted by year\n",
    "statehood_df1 = statehood_df1.sort_values(by='statehood_year').reset_index(drop=True)\n",
    "\n",
    "statehood_df1 = statehood_df1.drop(columns=['state_abbrev'])\n",
    "\n",
    "statehood_df1 = statehood_df1.rename(columns={'index': 'state_count', 'statehood_year': 'year'})\n",
    "\n",
    "num_of_states = statehood_df1[statehood_df1['year'] >= 1834]\n",
    "\n",
    "print(statehood_df1.head(10))\n",
    "\n",
    "num_of_states_final = final_df['year'].value_counts()\n",
    "\n",
    "print(num_of_states_final.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  num_states_statehood  num_states_final\n",
      "0  1834                  24.0                24\n",
      "1  1835                  24.0                24\n",
      "2  1836                  25.0                25\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'num_states_statehood'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/Revekka_first_environment/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_states_statehood'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[921], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_num_of_years\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Filter the rows where the two columns do not align\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m mismatched_rows \u001b[38;5;241m=\u001b[39m merged_num_of_states[merged_num_of_states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_states_statehood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m merged_num_of_states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_states_final\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Display the mismatched rows with all relevant columns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(mismatched_rows[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_states_statehood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_states_final\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Revekka_first_environment/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Revekka_first_environment/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_states_statehood'"
     ]
    }
   ],
   "source": [
    "merged_num_of_states = pd.merge(num_of_states, num_of_states_final, on='year', how='outer')\n",
    "\n",
    "merged_num_of_states = merged_num_of_states.rename(\n",
    "    columns={\n",
    "        'num_states': 'num_states_statehood',  \n",
    "        'count': 'num_states_final'           \n",
    "    }\n",
    ")\n",
    "print(merged_num_of_years.head(3))\n",
    "\n",
    "# Filter the rows where the two columns do not align\n",
    "mismatched_rows = merged_num_of_states[merged_num_of_states['num_states_statehood'] != merged_num_of_states['num_states_final']]\n",
    "\n",
    "# Display the mismatched rows with all relevant columns\n",
    "print(mismatched_rows[['year', 'num_states_statehood', 'num_states_final']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Revekka_first_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
