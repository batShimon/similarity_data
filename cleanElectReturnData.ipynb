{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Created by:** Revekka Gershovich **When:** Dic 4, 2024 **Why:** To clean and aggregate election returns data for years 1824 to 1968 from ICPSR 1, United States Historical Election Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(\"/Users/revekkagershovich/Dropbox (MIT)/StateLaws\")\n",
    "os.chdir(parent_dir)\n",
    "assert os.path.exists(parent_dir), \"parent_dir does not exist\"\n",
    "intermed_data_dir = \"./2_data/2_intermediate/political_data\"\n",
    "assert os.path.exists(intermed_data_dir), \"Data directory does not exist\"\n",
    "raw_data_dir = \"./2_data/1_raw/political_data\"\n",
    "assert os.path.exists(raw_data_dir), \"Data directory does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path.join(raw_data_dir, \"./ICPSR_election_returns/DS0001/00001-0001-Data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(path.join(raw_data_dir, \"./ICPSR_election_returns/DS0171/00001-0171-Data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5 = pd.read_csv(path.join(raw_data_dir, \"./ICPSR_election_returns/DS0005/00001-0005-Data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ICPR_STATE_CODE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get all column names from df\n",
    "column_names = df.columns\n",
    "print(len(column_names))\n",
    "\n",
    "# Step 2: Filter columns that start with 'X' followed by three digits (X###)\n",
    "pattern = re.compile(r\"^X\\d{3}_\")\n",
    "filtered_columns = [col for col in column_names if pattern.match(col)]\n",
    "print(len(filtered_columns))\n",
    "print(len(column_names) - len(filtered_columns))\n",
    "\n",
    "# Step 3: Remove the 'X###_' prefix\n",
    "cleaned_columns = {re.sub(r\"^X\\d{3}_\", \"\", col) for col in filtered_columns}\n",
    "\n",
    "# Step 4: Count unique column names after removing the prefix\n",
    "num_unique_columns = len(cleaned_columns)\n",
    "\n",
    "print(f\"Total number of columns after 1st melt should be {num_unique_columns + (len(column_names) - len(filtered_columns))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciphering variable names\n",
    "\n",
    "**1.** Since this dataset is provided in ASCII format with a SAS or SPSS setup files, I have extracted all the dataset into a csv format using a very niche R library called asciiSetupReader written specifically for extraction of pre-2000s dataset formatted in this weird way. As variable names in CSV, I used labels defined in the setup file. You can find this file in our StateLaws Dropbox: the path to the file is 1_code/similarity_code/Political_similarity_code/ICSPR_00001_to_csv.R\n",
    "\n",
    "**2.** \"Scope of Project\" documentation for the study that can be found here: https://www.icpsr.umich.edu/web/ICPSR/studies/1. According to it \"There is no actual codebook for this collection. Variable information is contained in the setup files.\" Thus, here I am making a codebook for naming conventions in my file so that if I or anyone else ever needs to go to the raw data, they would not have to spend hours figuring out what variable in the raw data mean. \n",
    "\n",
    "# Codebook for ICPSR 1, United States Historical Election Returns\n",
    "\n",
    "## State and County Identifiers\n",
    "| **Column Name**         | **Description**                                                                                     |\n",
    "|-------------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| `ICPR_STATE_CODE`       | ICPSR standardized state code.                                                                      |\n",
    "| `COUNTY_NAME`           | Standardized county name.                                                                           |\n",
    "| `IDENTIFICATION_NUMBER` | Unique numeric identifier for each county, enabling consistent referencing.                         |\n",
    "\n",
    "## Congressional District Numbers\n",
    "| **Column Name**           | **Description**                                                                                   |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| `CONG_DIST_NUMBER_YYYY`   | Congressional district number for a specific year (e.g., `CONG_DIST_NUMBER_1825`). May indicate the number of districts for split counties. |\n",
    "\n",
    "## Election Results\n",
    "\n",
    "### General Format\n",
    "\n",
    "X###_##_TYPE_RACE_PARTYCODE_VOTE\n",
    "\n",
    "### Components\n",
    "| **Component**     | **Description**                                                                                           |\n",
    "|-------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| `X###`           | Election year (e.g., `X824` = 1824).                                                                      |\n",
    "| `##`             | Election type/level: <br> **1** = Presidential, **2** = Gubernatorial, **3** = Congressional/House elections. |\n",
    "| `TYPE`           | Type of election: <br> **G** = General, **M** = Midterm, **S** = Special.                                 |\n",
    "| `RACE`           | Race type: <br> Examples: `PRES` = President, `GOV` = Governor.                                           |\n",
    "| `PARTYCODE`      | Code representing the political party. See the attached party codes file for definitions (e.g., `0025` = National Republican). |\n",
    "| `VOTE`           | Number of votes received by the candidate.                                                                |\n",
    "| `TOTAL_VOTE`     | Total votes cast for the specific race or election.                                                       |\n",
    "\n",
    "### Examples\n",
    "| **Column Name**               | **Description**                                                                             |\n",
    "|-------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| `X824_1_G_PRES_0025_VOTE`     | Votes for the National Republican candidate in the 1824 presidential general election.      |\n",
    "| `X825_2_G_GOV_0659_VOTE`      | Votes for a specific party in the 1825 gubernatorial general election.                      |\n",
    "| `X827_3_M_H_AL_9001_VOTE`     | Votes in a midterm House election in district `9001` for Alabama in 1827.                   |\n",
    "| `X836_2_G_GOV_TOTAL_VOTE`     | Total gubernatorial votes in the 1836 general election.                                     |\n",
    "\n",
    "## Handling Duplicate or Corrected Entries\n",
    "| **Column Name Example**       | **Description**                                                                             |\n",
    "|-------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| `X825_2_G_GOV_0659_VOTE.1`    | A vote for a second candidate from '0659' party in 1825 gubernatorial election.|\n",
    "| `X831_3_M_H_AL_0100_VOTE.2`   | A duplicate or re-evaluated entry for midterm House votes in district `0100` for Alabama in 1831. |\n",
    "\n",
    "## Important Notes\n",
    "- **Corrections:** Some entries, such as Jackson County in Georgia (`ID: 1510`), should be corrected to `1570` when analyzing by county.\n",
    "- **Missing Values:** For counties not reporting data or not participating in elections, identifiers like `98` (placeholders) are used.\n",
    "- **Party Codes:** Refer to the party codes section of the documentation contained in /Users/revekkagershovich/Dropbox (MIT)/StateLaws/2_data/1_raw/political_data/ICPSR_election_returns/DS0204/00001-0204-Documentation.txt for the specific meaning of codes like `0025`, `0659`, etc. which represent political parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding out what .1 .2 and .3 mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Melt To Make Year a Separate Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[col for col in df.columns if col.startswith('CONG')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify columns and group them by their suffix\n",
    "# Add all variables starting with \"CONG\" to id_vars\n",
    "id_vars = ['ICPR_STATE_CODE', 'COUNTY_NAME', 'IDENTIFICATION_NUMBER']\n",
    "grouped_columns = {}\n",
    "\n",
    "# Group columns by their suffix (everything after the first underscore and without the year part)\n",
    "for col in df.columns:\n",
    "    if col.startswith('X'):\n",
    "        suffix = '_'.join(col.split('_')[1:])  # Extract the suffix after the first underscore\n",
    "        if suffix not in grouped_columns:\n",
    "            grouped_columns[suffix] = []\n",
    "        grouped_columns[suffix].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reshape each group and combine into a single table\n",
    "reshaped_dataframes = []\n",
    "\n",
    "for suffix, cols in grouped_columns.items():\n",
    "    # Reshape the group into long format\n",
    "    temp_df = pd.melt(df, id_vars=id_vars, value_vars=cols,\n",
    "                      var_name='year', value_name=suffix)\n",
    "    # Extract the year and adjust to full year format\n",
    "    temp_df['year'] = temp_df['year'].str.extract(r'X(\\d+)').astype(int) + 1000\n",
    "    reshaped_dataframes.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge all reshaped groups into a single DataFrame\n",
    "final_df = reshaped_dataframes[0]\n",
    "for additional_df in reshaped_dataframes[1:]:\n",
    "    final_df = final_df.merge(additional_df, on=id_vars + ['year'], how='outer')\n",
    "\n",
    "final_df = final_df[['year'] + [col for col in final_df.columns if col != 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = final_df[final_df['2_G_GOV_0026_VOTE.1'].notna()]\n",
    "\n",
    "# print(temp['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = final_df[final_df['2_G_GOV_0659_VOTE.1'].notna()]\n",
    "\n",
    "# print(temp['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename TOTAL_VOTE columns to match the party code format ('0000' instead of a party code)\n",
    "renamed_columns = {col: col.replace(\"TOTAL_VOTE\", \"0000_VOTE\") for col in final_df.columns if \"TOTAL_VOTE\" in col}\n",
    "\n",
    "final_df = final_df.rename(columns=renamed_columns)\n",
    "\n",
    "# Rename OTHER_VOTE columns to match the party code format ('0000' instead of a party code)\n",
    "renamed_columns = {col: col.replace(\"OTHER_VOTE\", \"3000_VOTE\") for col in final_df.columns if \"OTHER_VOTE\" in col}\n",
    "\n",
    "final_df = final_df.rename(columns=renamed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Candidates From A Single Party\n",
    "Dealing with situation where multiple candidate exists in single elections for a single party, i.e. there are 3 Opposition Republicans running for 1825 CT elections. \n",
    "\n",
    "1. I compared the election of 1825 in CT to Wikipedia data and discovered that one of the parties had 3 candidates, and in the data this party had .1 and .2 prefixes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exploring why some variables have version with suffixes .1, .2, etc. in the dataset\n",
    "# # Step 1: Filter the dataset for the year 1825\n",
    "# elec_1825 = final_df[final_df['year'] == 1825]\n",
    "\n",
    "# # Step 2: Select columns that include 'COUNTY_NAME' and those starting with '2_G_GOV'\n",
    "# selected_columns = ['COUNTY_NAME'] + [col for col in final_df.columns if col.startswith(\"2_G_GOV\")]\n",
    "\n",
    "# # Step 3: Keep only the selected columns\n",
    "# elec_1825 = elec_1825[selected_columns]\n",
    "\n",
    "# # Step 4: Drop columns that contain only NA values\n",
    "# elec_1825 = elec_1825.dropna(axis=1, how='all')\n",
    "\n",
    "# # Display the resulting dataframe\n",
    "# print(elec_1825)\n",
    "\n",
    "# #0012  OLD REPUBLICAN \n",
    "# #0001 FEDERALIST\n",
    "# #0659 Opposition Republicans\n",
    "\n",
    "# total_votes = elec_1825[\"2_G_GOV_0000_VOTE\"].sum()\n",
    "# print(f\"Total votes for 2_G_GOV_0000_VOTE: {total_votes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify columns with suffixes .1, .2, .3, etc.\n",
    "suffix_pattern = re.compile(r\"(.*)\\.(\\d+)$\")  # Matches columns ending in .1, .2, etc.\n",
    "grouped_columns = {}\n",
    "\n",
    "for col in final_df.columns:\n",
    "    match = suffix_pattern.match(col)\n",
    "    if match:\n",
    "        base_name = match.group(1)  # Extract base column name (without suffix)\n",
    "        if base_name not in grouped_columns:\n",
    "            grouped_columns[base_name] = []\n",
    "        grouped_columns[base_name].append(col)\n",
    "\n",
    "# Step 2: Identify related columns and rename base columns with .0 postfix\n",
    "for base_name in grouped_columns.keys():\n",
    "    if base_name in final_df.columns:  # If the original base column exists\n",
    "        final_df.rename(columns={base_name: base_name + \".0\"}, inplace=True)\n",
    "        grouped_columns[base_name].append(base_name + \".0\")  # Include renamed base column\n",
    "\n",
    "# Step 3: Create new summed columns\n",
    "for base_name, related_columns in grouped_columns.items():\n",
    "    final_df[base_name] = final_df[related_columns].sum(axis=1)\n",
    "\n",
    "# Step 4: Drop all columns with suffixes .0, .1, .2, etc.\n",
    "columns_to_drop = [col for col in final_df.columns if re.search(r\"\\.\\d+$\", col)]\n",
    "final_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melt 2\n",
    "## Removing party from the name into a separate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify columns and group them by their base name (e.g., `2_G_GOV_VOTE`)\n",
    "id_vars = ['ICPR_STATE_CODE', 'COUNTY_NAME', 'IDENTIFICATION_NUMBER', 'year'] + [col for col in df.columns if col.startswith('CONG')]\n",
    "grouped_columns = {}\n",
    "\n",
    "# Group columns by removing the numeric segment before \"_VOTE\" (the second-to-last segment)\n",
    "for col in final_df.columns:\n",
    "    if '_VOTE' in col:  # Ensure we're only processing relevant columns\n",
    "        parts = col.split('_')\n",
    "        base_name = '_'.join(parts[:-2] + ['VOTE']) if parts[-2].isdigit() else col  # Remove numeric part before \"VOTE\"\n",
    "        \n",
    "        if base_name not in grouped_columns:\n",
    "            grouped_columns[base_name] = []\n",
    "        grouped_columns[base_name].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reshape each group and combine into a single table\n",
    "reshaped_dataframes = []\n",
    "\n",
    "for base_name, cols in grouped_columns.items():\n",
    "    # Reshape the group into long format\n",
    "    temp_df = pd.melt(final_df, id_vars=id_vars, value_vars=cols,\n",
    "                      var_name='party', value_name=base_name)\n",
    "\n",
    "\n",
    "    # Extract the 4-digit party code from column names\n",
    "    extracted_party = temp_df['party'].str.extract(r'_(\\d{4})_')\n",
    "    temp_df['party'] = extracted_party[0]  # Get first column from extracted DataFrame\n",
    "\n",
    "    reshaped_dataframes.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge all reshaped groups into a single DataFrame\n",
    "final_df = reshaped_dataframes[0]\n",
    "for additional_df in reshaped_dataframes[1:]:\n",
    "    final_df = final_df.merge(additional_df, on=id_vars + ['party'], how='outer')\n",
    "\n",
    "final_df = final_df[['party'] + [col for col in final_df.columns if col != 'party']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['party'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.pivot_table(index='COUNTY_NAME', columns='year', aggfunc='size', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.rename(columns={'ICPR_STATE_CODE': 'ICPSR_state_code', 'COUNTY_NAME': 'county_name', \n",
    "                        'IDENTIFICATION_NUMBER': 'county_id'\n",
    "}, inplace=True)\n",
    "\n",
    "final_df['county_name'] = final_df['county_name'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ICPSR to FIPS and ICPSR to State Name mappings\n",
    "icpsr_to_fips = {\n",
    "    1: 9,  2: 23, 3: 25, 4: 33, 5: 44, 6: 50, 11: 10, 12: 34, 13: 36, 14: 42, 21: 17,\n",
    "    22: 18, 23: 26, 24: 39, 31: 19, 32: 20, 33: 27, 34: 29, 35: 31, 36: 38, 37: 46,\n",
    "    40: 51, 41: 1, 42: 5, 43: 12, 44: 13, 45: 22, 46: 28, 47: 37, 48: 45, 49: 48,\n",
    "    51: 21, 52: 24, 53: 40, 54: 47, 56: 54, 49: 48, 72: 41, 73: 53, 97: 97, 98: 11\n",
    "}\n",
    "\n",
    "# Add 'state_fips' column to cong_df based on 'ICPSR_state_code'\n",
    "final_df['state_fips'] = final_df['ICPSR_state_code'].map(icpsr_to_fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to keep (these should not be considered when checking for empty/zero rows)\n",
    "columns_to_exclude = ['party', 'ICPSR_state_code', 'county_name', 'county_id', 'year', 'state_fips']\n",
    "\n",
    "# Identify numeric columns that should be checked for being empty or zero\n",
    "columns_to_check = [col for col in final_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Drop rows where all of the columns in `columns_to_check` are either NaN or 0\n",
    "final_df = final_df[~(final_df[columns_to_check].isna() | (final_df[columns_to_check] == 0)).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to group by (state-level aggregation by party-year pair)\n",
    "groupby_columns = ['party', 'year', 'state_fips']\n",
    "\n",
    "# Define columns to exclude from summation\n",
    "columns_to_exclude = ['party', 'ICPSR_state_code', 'county_name', 'county_id', 'year', 'state_fips']\n",
    "\n",
    "# Define columns to sum (all columns except those in columns_to_exclude)\n",
    "columns_to_sum = [col for col in final_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "\n",
    "# Perform aggregation by summing vote counts at the state level\n",
    "final_df = final_df.groupby(groupby_columns, as_index=False)[columns_to_sum].sum()\n",
    "\n",
    "# Display the aggregated dataset\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**1.** I should check that all the columns were melted correctly: it seems like some columns such as columns with different versions and such were dropped as well as AL columns. \n",
    "\n",
    "**2.** Start loading data in a loop for all states, and potentially concatinate it into one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Revekka_first_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
